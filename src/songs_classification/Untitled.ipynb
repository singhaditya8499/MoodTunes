{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896b60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fdf3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/moody_lyrics_small_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe422d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy      188\n",
       "angry      124\n",
       "sad        122\n",
       "relaxed    103\n",
       "Name: Mood, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Mood.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05bf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Angry = 0, Happy = 1, Relaxed = 2, Sad = 3\n",
    "def getMoodNumeric(x):\n",
    "    if x == \"angry\":\n",
    "        return 0\n",
    "    elif x == \"happy\":\n",
    "        return 1\n",
    "    elif x == \"relaxed\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "data[\"Mood_Numeric\"] = data.Mood.apply(getMoodNumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ab0554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../../data/moody_mood_numeric.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ec5ed",
   "metadata": {},
   "source": [
    "## Transformer for model start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7075252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--lr LR] [--epochs EPOCHS] [--ml ML]\n",
      "                             [--bs BS] [--ts TS] [--adaptive ADAPTIVE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/adityasingh/Library/Jupyter/runtime/kernel-f2cc1e7c-fe6a-427e-a6cb-1adb502f29c9.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasingh/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, precision_recall_fscore_support, f1_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetModel, AdamW\n",
    "import argparse\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "def logging_storage(logfile_path):\n",
    "    logging.basicConfig(filename=logfile_path, filemode='a', level=logging.INFO, format='%(asctime)s => %(message)s')\n",
    "    logging.info(torch.__version__)\n",
    "    logging.info(device)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr', help='Learning Rate', default=2e-5, type=float)\n",
    "parser.add_argument('--epochs', help='Number of Epochs', default=20, type=int)\n",
    "parser.add_argument('--ml', help='Max Len of Sequence', default=1024, type=int)\n",
    "parser.add_argument('--bs', help='Batch Size', default=8, type=int)\n",
    "parser.add_argument('--ts', help='Test Size', default=0.2, type=float)\n",
    "parser.add_argument('--adaptive', help='Adaptive LR', default='20', type=float)\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "lr = args.lr\n",
    "num_epochs = args.epochs\n",
    "MAX_LEN = args.ml\n",
    "batch_size = args.bs\n",
    "test_size = args.ts\n",
    "model = 'xlnet'\n",
    "num_labels = 4\n",
    "denom = args.adaptive\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "ending_path = ('%s_%d_bs_%d_adamw_data_%d_lr_%s_%d' %(model, MAX_LEN, batch_size,(1 - test_size)*100, str(lr).replace(\"-\",\"\"),denom))\n",
    "ending_path\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "save_model_path = \"../models/\" + ending_path\n",
    "if not os.path.exists(save_model_path):\n",
    "    os.mkdir(save_model_path)\n",
    "if not os.path.exists(\"../logs/\"):\n",
    "    os.mkdir(\"../logs/\")\n",
    "logfile_path = \"../logs/\" + ending_path\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "logging_storage(logfile_path)\n",
    "\n",
    "\n",
    "# ## Data Loading\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
    "\n",
    "df = data\n",
    "\n",
    "#df = pd.read_csv('../../data/moody_lyrics_small_dataset.csv', index_col = 0)\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "songs = df['lyrics'].tolist()\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(song) for song in songs]\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "### Angry = 0, Happy = 1, Relaxed = 2, Sad = 3\n",
    "\n",
    "\n",
    "output_moods = df['Mood_Numeric'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# ## Process ML\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, output_moods, \n",
    "                                                            random_state=2018, test_size=test_size)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=test_size)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "logging.info(\"Model Loaded!\")\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                     lr=lr)\n",
    "\n",
    "# ## Helper functions\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    labels_flat = labels_flat.cpu().detach().numpy() \n",
    "    return np.sum(pred_flat == labels_flat), pred_flat\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "def train(i):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_predicted_label = np.array([])\n",
    "    total_actual_label = np.array([])\n",
    "    train_len = 0\n",
    "    f_acc = 0\n",
    "    \n",
    "    ## adaptive lr\n",
    "    optimizer.param_groups[0]['lr'] *= (0.1)**(1/denom)\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        if b_labels.size(0) <= 1:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        pred = outputs[1].detach().cpu().numpy()\n",
    "        batch_f_acc, pred_flat = flat_accuracy(pred, b_labels)\n",
    "        f_acc += batch_f_acc\n",
    "        loss = outputs[0]\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        labels_flat = b_labels.flatten().cpu().detach().numpy()\n",
    "        total_actual_label = np.concatenate((total_actual_label, labels_flat))\n",
    "        total_predicted_label = np.concatenate((total_predicted_label, pred_flat))\n",
    "        \n",
    "        total_loss += outputs[0].sum()\n",
    "        train_len += b_input_ids.size(0)\n",
    "        \n",
    "        if step%100 == 0 and step:\n",
    "            precision, recall, f1_measure, _ =  precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "            logging.info(\"Train: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" %(train_len*100.0/train_inputs.size(0), i, step,total_loss/train_len, f_acc*100.0/train_len,precision*100., recall*100., f1_measure*100.))\n",
    "\n",
    "        # if torch.cuda.device_count() > 1:\n",
    "        #     p = 100\n",
    "        #     path = save_model_path + '/e_' + str(i) + \"_\" + str(p) + \".ckpt\"\n",
    "        #     torch.save(model.module.state_dict(), path)\n",
    "        # else:\n",
    "        #     torch.save(model.state_dict(), path)\n",
    "\n",
    "    precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "    logging.info(\"Train: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" %(train_len*100.0/train_inputs.size(0), i, step,total_loss/train_len, f_acc*100.0/train_len, precision*100., recall*100., f1_measure*100.))\n",
    "\n",
    "# In[44]:\n",
    "def eval(i):\n",
    "    model.eval()\n",
    "    val_len = 0\n",
    "    total_loss = 0\n",
    "    total_predicted_label = np.array([])\n",
    "    total_actual_label = np.array([])\n",
    "    f_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            pred = outputs[1].detach().cpu().numpy()\n",
    "            batch_f_acc, pred_flat = flat_accuracy(pred, b_labels)\n",
    "            f_acc += batch_f_acc\n",
    "            \n",
    "            labels_flat = b_labels.flatten().cpu().detach().numpy()\n",
    "            total_actual_label = np.concatenate((total_actual_label, labels_flat))\n",
    "            total_predicted_label = np.concatenate((total_predicted_label, pred_flat))\n",
    "            \n",
    "            val_len += b_input_ids.size(0)\n",
    "            total_loss += outputs[0].sum()\n",
    "\n",
    "        if step%100 == 0 and step:\n",
    "            precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "            logging.info(\"Eval: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" %(val_len*100.0/validation_inputs.size(0), i, step,total_loss/val_len, f_acc*100.0/val_len,precision*100., recall*100., f1_measure*100.))\n",
    "    \n",
    "    precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
    "    logging.info(\"Eval: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" %(val_len*100.0/validation_inputs.size(0), i, step,total_loss/val_len, f_acc*100.0/val_len,precision*100., recall*100., f1_measure*100.))\n",
    "        \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    train(i)\n",
    "    eval(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172b0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
